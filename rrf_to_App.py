import re
import subprocess
import tkinter as tk
from tkinter import filedialog
import os
import json
import importlib.util
# ======ã€è¨­å®šå€ã€‘======
SHOW_OFFSET = False# é¡¯ç¤º slot åœ¨ group å…§çš„ offset ä½ç½®
SHOW_RAW = False# é¡¯ç¤º slot çš„åŸå§‹ bytesï¼ˆæ¯8é¡†ä¸€è¡Œï¼‰
SHOW_2201 = True# é¡¯ç¤º 2201 slot å¡ç‰‡è§£æ
SHOW_2301 = True# é¡¯ç¤º 2301 slot è£å‚™è§£æ
SHOW_2701 = True# é¡¯ç¤º 2701 slot è§£æï¼ˆç²¾ç…‰ç­‰ç´šï¼‰
SHOW_2D01 = True# é¡¯ç¤º 2D01 slot é™„é­”è§£æ
SHOW_2B01 = True# é¡¯ç¤º 2B01 slot è£å‚™éšç´š
SHOW_GROUPS = []#åªé¡¯ç¤ºæŒ‡å®šçš„ groupç·¨è™Ÿï¼Œç©ºåˆ—è¡¨/Noneä»£è¡¨é¡¯ç¤ºå…¨éƒ¨ï¼Œå¦‚ [1,3] åªé¡¯ç¤ºç¬¬1å’Œç¬¬3å€‹group
SHOW_GROUP_NAMES = []# ä¾‹å¦‚ ['é ­ä¸‹', 'ç›¾ç‰Œ'] åªé¡¯ç¤ºé€™å…©å€‹éƒ¨ä½, ç©ºçš„è©±å…¨éƒ¨é¡¯ç¤º
SHOW_ONLY_FILLED = True     # åªé¡¯ç¤ºæœ‰è³‡æ–™çš„éƒ¨ä½ï¼ˆgroupï¼‰
SHOW_ONLY_PARSED_SLOTS = True   # åªé¡¯ç¤ºæœ‰è§£æ/é–‹é—œé–‹å•Ÿçš„ slot
# ======================
GRADE_MAP = {
    0: "N",
    1: "D",
    2: "C",
    3: "B",
    4: "A"
}
GROUP_NAME_MAP = {
    1: 'é ­ä¸‹',
    2: 'å³æ‰‹(æ­¦å™¨)',
    3: 'æŠ«è‚©',
    4: 'é£¾å“å³',
    5: 'é§ç”²',
    6: 'å·¦æ‰‹(ç›¾ç‰Œ)',
    7: 'é‹å­',
    8: 'é£¾å“å·¦',
    9: 'é ­ä¸Š',
    10: 'é ­ä¸­',
}
Shadow_GROUP_NAME_MAP = {

    1: 'æœé£¾é ­ä¸‹',
    2: 'å½±å­æ‰‹å¥—',
    3: 'æœé£¾æ–—ç¯·',
    4: 'å½±å­è€³ç’°å³',
    5: 'å½±å­é§ç”²',
    6: 'å½±å­ç›¾ç‰Œ',
    7: 'å½±å­é‹å­',
    8: 'å½±å­å¢¬å­å·¦',
    9: 'æœé£¾é ­ä¸Š',
    10: 'æœé£¾é ­ä¸­',
}


def load_python_dict(path, var_name):
    """
    å¾å¤–éƒ¨ .py æª”è¼‰å…¥æŒ‡å®šè®Šæ•¸ã€‚
    
    path: å¤–éƒ¨ .py æª”æ¡ˆè·¯å¾‘
    var_name: è¦è®€å–çš„ dict è®Šæ•¸åç¨±ï¼Œä¾‹å¦‚ 'all_skill_entries'
    """
    if not os.path.exists(path):
        raise FileNotFoundError(f"å¤–éƒ¨è³‡æ–™æª”ä¸å­˜åœ¨: {path}")

    spec = importlib.util.spec_from_file_location("external_module", path)
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)

    if not hasattr(module, var_name):
        raise AttributeError(f"{path} è£¡æ‰¾ä¸åˆ°è®Šæ•¸: {var_name}")

    return getattr(module, var_name)


job_dict = load_python_dict("data/job_dict.py", "job_dict")#è·æ¥­job_id


import sys, os
def resource_path(rel_path):
    if hasattr(sys, '_MEIPASS'):
        return os.path.join(sys._MEIPASS, rel_path)
    return os.path.join(os.path.abspath("."), rel_path)


# è¼‰å…¥EnumVAR.lua
with open("data/enumvar.lua", "r", encoding="utf-8") as f:
    enum_lua = f.read()

# è§£æ EnumVARï¼š104 -> RACE_DAMAGE_HUMAN
id_to_key = {}
enumvar_pat = re.compile(r'(\w+)\s*=\s*{\s*(\d+)\s*,\s*(\d+)\s*}', re.MULTILINE)
for m in enumvar_pat.finditer(enum_lua):
    key, k1, k2 = m.group(1), int(m.group(2)), int(m.group(3))
    id_to_key[k1] = key
    # éƒ¨åˆ†è¡¨æ ¼åè‘—ä¹Ÿè¦æ”¯æ´ï¼Œåƒ { 104, 7 } ï¼Œé™„é­”ID 104ã€value 7


# è®€ AddRandomOptionNameTable.lua
with open("data/AddRandomOptionNameTable.lua", "r", encoding="utf-8") as f:
    addopt_lua = f.read()

# EnumVAR.KEY[1] = "ä¸­æ–‡æè¿°"
key_to_desc = {}
desc_pat = re.compile(r'\[EnumVAR\.([A-Z0-9_]+)\[1\]\]\s*=\s*"([^"]+)"')
for m in desc_pat.finditer(addopt_lua):
    key = m.group(1)  # EnumVAR åç¨±
    desc = m.group(2)
    key_to_desc[key] = desc

with open("data/EnchantName.lua", "r", encoding="utf-8") as f:
    enchant_lua = f.read()

key_to_jsonfmt = {}
json_pat = re.compile(r'\[EnumVAR\.([A-Z0-9_]+)\[1\]\]\s*=\s*"([^"]+)"')
for m in json_pat.finditer(enchant_lua):
    key = m.group(1)
    fmt = m.group(2)
    key_to_jsonfmt[key] = fmt




def get_enchant_info(enchant_id, value):
    """
    return: (é¡¯ç¤ºç”¨ä¸­æ–‡, JSONç”¨æ ¼å¼å­—ä¸²)
    """

    # Step1: æ‰¾ enumvar key åç¨±
    key = id_to_key.get(enchant_id)
    if not key:
        return ("", "")   # ç„¡é™„é­” or ä¸æ”¯æ´ ID

    # Step2: æ‰¾ä¸­æ–‡é™„é­”æè¿°
    desc_fmt = key_to_desc.get(key, "")
    if desc_fmt:
        try:
            desc_text = desc_fmt % value
        except:
            desc_text = f"{desc_fmt} ({value})"
    else:
        desc_text = f"{key} +{value}"

    # Step3: æ‰¾ JSON æ ¼å¼ (AddExtParam...)
    json_fmt = key_to_jsonfmt.get(key, "")
    if json_fmt:
        json_text = json_fmt.replace("%d", str(value))
    else:
        json_text = ""

    return (desc_text, json_text)



# ================================================================
# ä½ çš„ iteminfo parserï¼ˆç…§ä½ çµ¦çš„ä¿ç•™ï¼‰
# ================================================================
def parse_lub_file(filename):
    try:
        with open(filename, "r", encoding="utf-8") as file:
            content = file.read()
    except FileNotFoundError:
        QMessageBox.critical(None, "éŒ¯èª¤", f"æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{filename}")
        return {}

    item_entries = re.findall(
        r"\[(\d+)\]\s*=\s*{(.*?)}(?=,\s*\[\d+\]|\s*\[\d+\]|\s*$)",
        content,
        re.DOTALL
    )

    parsed_items = {}
    for item_id, body in item_entries:
        try:
            item_id = int(item_id)

            identified_name = re.search(r'(?<!un)identifiedDisplayName\s*=\s*"([^"]+)"', body)
            kr_name = re.search(r'(?<!un)identifiedResourceName\s*=\s*"([^"]+)"', body)
            slot = re.search(r'slotCount\s*=\s*(\d+)', body)

            # æè¿°
            desc_match = re.search(r'(?<!un)identifiedDescriptionName\s*=\s*{(.*?)}', body, re.DOTALL)
            if desc_match:
                desc_body = desc_match.group(1)
                desc_lines_raw = re.findall(r'"([^"]*)"', desc_body)
                desc_lines = [line.strip() for line in desc_lines_raw]
            else:
                desc_lines = []

            if identified_name and kr_name and slot:
                base_name = identified_name.group(1).strip()
                slot_count = int(slot.group(1))

                display_name = f"{base_name} [{slot_count}]" if slot_count > 0 else base_name

                parsed_items[item_id] = {
                    "name": display_name,
                    "base_name": base_name,
                    "kr_name": kr_name.group(1).strip(),
                    "description": desc_lines,
                    "slot": slot_count
                }

        except:
            pass

    return parsed_items

def parse_equipment_blocks(content):
    import re

    blocks = {}
    pattern = re.compile(r"\[(\d+)\]\s*=\s*{", re.MULTILINE)
    matches = list(pattern.finditer(content))
    total = len(matches)
    #print(f"ğŸ“¦ é–‹å§‹è§£æè£å‚™å€å¡Šï¼Œå…± {total} ç­†è³‡æ–™")

    for i, match in enumerate(matches):
        item_id = int(match.group(1))
        start = match.end()
        end = matches[i+1].start() if i+1 < len(matches) else len(content)

        block_text = content[start:end].strip()

        # åŠ å›å®Œæ•´å¤§æ‹¬è™ŸåŒ…è£¹ï¼Œç¢ºä¿ block æ ¼å¼æ­£ç¢º
        block_text_full = "{" + block_text.rstrip(",") + "}"

        blocks[item_id] = block_text_full
        #print(f"  â†’ è™•ç†ä¸­ {i+1}/{total} ç­†", end="\r")
    #print(f"\nâœ… è§£æå®Œæˆï¼Œå…± {len(blocks)} ç­†è£å‚™ã€‚")
    return blocks


def resolve_name_conflicts(parsed_items, equipment_blocks):
    """
    parsed_items: parse_lub_file() çš„çµæœ
    equipment_blocks: parse_equipment_blocks() çš„çµæœ
    åªå°æœ‰èƒ½åŠ›å€å¡Šçš„ itemID åŸ·è¡Œåç¨±é‡è¤‡è™•ç†
    """

    # åªå–å‡ºã€Œæœ‰èƒ½åŠ›ã€çš„ç‰©å“
    affected_items = {
        item_id: parsed_items[item_id]
        for item_id in equipment_blocks.keys()
        if item_id in parsed_items
    }

    # çµ±è¨ˆåç¨±å‡ºç¾æ¬¡æ•¸
    name_count = {}
    for item_id, info in affected_items.items():
        name = info["name"]
        name_count[name] = name_count.get(name, 0) + 1

    # åªæœ‰é‡è¤‡åç¨±éœ€è¦åŠ  itemID
    for item_id, info in affected_items.items():
        name = info["name"]
        if name_count[name] > 1:
            #print(f"{name}")
            info["name"] = f"{name} (ID:{item_id})"

    # æ³¨æ„ï¼šparsed_items æœ¬èº«ä¹Ÿæœƒè¢«æ›´æ–°ï¼ˆå› ç‚º dict æ˜¯åƒè€ƒï¼‰
    return parsed_items

def load_skill_map(filepath=None):
    global skill_map, skill_map_all, skill_df
    import skill_tree
    import pandas as pd
    import os

    # è‹¥ filepath æ²’æŒ‡å®š â†’ ä¸åšä»»ä½•äº‹
    if filepath is None:
        print("æœªæŒ‡å®šè·¯å¾‘ï¼Œä½¿ç”¨é è¨­ç©ºç™½æŠ€èƒ½åˆ—è¡¨ã€‚")
        return

    if not os.path.exists(filepath):
        print(f"{filepath} æ‰¾ä¸åˆ°ï¼Œä¿ç•™ç©ºç™½æŠ€èƒ½åˆ—è¡¨ã€‚")
        return

    skill_df = pd.read_csv(filepath)

    # === ItemSearchApp ç”¨ ===
    skill_map = dict(zip(skill_df["ID"], skill_df["Name"]))
    skill_map_all = skill_df.set_index("ID").to_dict(orient="index")

    # === skill_tree ç”¨ ===
    skill_tree.skill_id_to_name = dict(zip(skill_df["ID"], skill_df["Name"]))
    skill_tree.skill_code_to_id = dict(zip(skill_df["Code"], skill_df["ID"]))
    skill_tree.skill_code_to_name = dict(zip(skill_df["Code"], skill_df["Name"]))


    print("æŠ€èƒ½åˆ—è¡¨è¼‰å…¥æˆåŠŸ")




def run_replay_and_dump():
    # 1. é¸æ“‡ RRF
    root = tk.Tk()
    root.withdraw()

    rrf_path = filedialog.askopenfilename(
        title="é¸æ“‡ RRF æª”æ¡ˆ",
        filetypes=[("Ragnarok Replay Files", "*.rrf"), ("All Files", "*.*")]
    )
    if not rrf_path:
        print("ä½¿ç”¨è€…å–æ¶ˆé¸æ“‡ã€‚")
        return None, None

    # 2. æŒ‡å®š temp.txt è¼¸å‡ºä½ç½®
    output_txt = "tmp/temp.txt"

    # 3. åŸ·è¡Œå¤–éƒ¨ exe ä¸¦å°‡è¼¸å‡ºå¯«å…¥ temp.txt
    exe_path = "APP/RagnarokReplayExample.exe"  # å¦‚æœ exe ä¸åœ¨åŒè³‡æ–™å¤¾è«‹æ”¹æˆçµ•å°è·¯å¾‘

    cmd = f'"{exe_path}" "{rrf_path}" > "{output_txt}"'

    print("åŸ·è¡Œä¸­ï¼š", cmd)
    subprocess.run(cmd, shell=True)

    # 4. å›å‚³ temp.txt è·¯å¾‘
    if os.path.exists(output_txt):
        print("è§£æå®Œæˆï¼Œå·²ç”¢ç”Ÿï¼š", output_txt)
        return rrf_path, output_txt

    print("éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° temp.txt")
    return rrf_path, None

#æˆªå–æŠ€èƒ½ç­‰ç´š
import string

def is_valid_skill_name(s):
    # æŠ€èƒ½åè‡³å°‘ 6 å€‹å­—å…ƒï¼Œå…¨éƒ¨ç”± A~Zã€0~9ã€_ çµ„æˆï¼Œä¸”å¿…é ˆåŒ…å« _
    if len(s) < 3:
        return False
    
    allowed = string.ascii_uppercase + string.digits + "_"
    
    for ch in s:
        if ch not in allowed:
            return False
    
    # æ–°å¢ï¼šä¸€å®šè¦è‡³å°‘æœ‰ä¸€å€‹ _
    if "_" not in s:
        return False
    
    return True



def parse_skillinfo_list_from_text(content):
    # ç”¨ find å–æœ€å¤–å±¤ {}
    start = content.find('{')
    end = content.rfind('}')
    if start == -1 or end == -1 or end <= start:
        return []

    block = content[start+1:end]
    hex_list = re.findall(r'\b([0-9A-Fa-f]{2})\b', block)
    n = len(hex_list)

    skills = []
    i = 0

    while i < n - 20:

        # å‰å…© byte ä¸ç‚º 00 â†’ åˆæ­¥å¯èƒ½æ˜¯æŠ€èƒ½å
        if hex_list[i] != "00" and hex_list[i+1] != "00":

            name_start = i

            # æŠ“æŠ€èƒ½åç›´åˆ° 00
            name_bytes = []
            j = i
            while j < n and hex_list[j] != "00":
                name_bytes.append(hex_list[j])
                j += 1

            # è½‰ ASCII
            try:
                name = bytes.fromhex("".join(name_bytes)).decode("ascii", errors="ignore")
            except:
                name = ""

            # â˜…â˜…â˜… åŠ ä¸Šé€™å€‹ï¼šä¸æ˜¯åˆæ³•æŠ€èƒ½å â†’ è·³é
            if not is_valid_skill_name(name):
                i += 1
                continue

            # å–æŠ€èƒ½ç­‰ç´šï¼ˆå‰ 6 bytes çš„é ­ 2 bytesï¼‰
            lvl_pos = name_start - 6
            level = 0
            if lvl_pos >= 0:
                lv_low = int(hex_list[lvl_pos], 16)
                lv_high = int(hex_list[lvl_pos + 1], 16)
                level = lv_high * 256 + lv_low

            skills.append((name, level))

            i = j + 1
        else:
            i += 1

    return skills





def bytes_to_int_le(b):
    return int(''.join(reversed(b)), 16)

import re

def extract_session_stats(filepath):
    with open(filepath, 'r', encoding='cp950', errors='ignore') as f:
        content = f.read()

    target_fields = [
        "Job", "Level", "JobLevel",
        "Str", "Agi", "Vit", "Int", "Dex", "Luk"
    ]

    results = {}

    # --------------------------
    # æ•¸å€¼é¡ (4 bytes)
    # --------------------------
    for field in target_fields:
        pat = (
            r"\[Chunk Session\] Unparsed opcode " + field +
            r", Length=4\s+â†’ Raw hex:[^\{]*\{([^}]*)\}"
        )
        m = re.search(pat, content, re.DOTALL)
        if not m:
            continue

        block = m.group(1)

        data_bytes = []
        for line in block.splitlines():
            line = line.strip()
            hexes = re.findall(r'\b([0-9A-Fa-f]{2})\b', line)
            if len(hexes) >= 4:
                data_bytes.extend(hexes[-4:])  # åªæŠ“æœ€å¾Œ 4 bytes

        if len(data_bytes) == 4:
            val = int(''.join(reversed(data_bytes)), 16)
            results[field] = val


    # --------------------------
    # HEADER_ZC_COUPLESTATUSï¼šè§£ææ‰€æœ‰å°åŒ…ï¼Œå–æœ€å¾Œæ›´æ–°
    # --------------------------
    pat_couple = r"packet HEADER_ZC_COUPLESTATUS.*?\{([^}]*)\}"
    all_matches = re.findall(pat_couple, content, re.DOTALL)

    # å°ç…§è¡¨
    attr_map = {
        0xdb: "POW",
        0xdc: "STA",
        0xdd: "WIS",
        0xde: "SPL",
        0xdf: "CON",
        0xe0: "CRT",
    }

    # é€ç­†è™•ç†ï¼Œå¾Œå‡ºç¾çš„æœƒè¦†è“‹å‰é¢çš„
    for block in all_matches:

        # æŠ“å…¨éƒ¨ hex bytes
        hex_list = re.findall(r'\b([0-9A-Fa-f]{2})\b', block)
        if len(hex_list) < 8:
            continue

        # ç¬¬ 3 byte = å±¬æ€§ IDï¼ˆindex 2ï¼‰
        attr_id = int(hex_list[2], 16)

        # ç¬¬ 7+8 byte = æ•¸å€¼ï¼ˆlittle-endianï¼‰
        low = int(hex_list[6], 16)
        high = int(hex_list[7], 16)
        value = (high << 8) | low

        # è‹¥ ID æœ‰åœ¨å°ç…§è¡¨ä¸­ -> è¨˜éŒ„ (å¾Œé¢å‡ºç¾çš„æœƒè¦†è“‹)
        if attr_id in attr_map:
            results[attr_map[attr_id]] = value

    # --------------------------
    # æ–°å¢ï¼šCharactername (64 bytesï¼ŒBig5)
    # --------------------------
    pat_name = (
        r"\[Chunk ReplayData\] Unparsed opcode Charactername, Length=64"
        r".*?Raw hex:[^\{]*\{([^}]*)\}"
    )
    m = re.search(pat_name, content, re.DOTALL)
    if m:
        block = m.group(1)
        hex_list = []

        for line in block.splitlines():
            line = line.strip()
            hexes = re.findall(r'\b([0-9A-Fa-f]{2})\b', line)
            # æ¯è¡Œæœ€å¤šå– 16 bytes (æ­£å¸¸ hex dump æ ¼å¼)
            hex_list.extend(hexes)

        # åªå– 64 bytes
        hex_list = hex_list[:64]

        # è½‰æˆ bytes
        raw_bytes = bytes(int(h, 16) for h in hex_list)

        # å»é™¤å¾Œé¢ NUL padding
        raw_bytes = raw_bytes.split(b'\x00', 1)[0]

        try:
            name = raw_bytes.decode('big5', errors='ignore')
        except:
            name = ""

        results["Charactername"] = name

    return results




def extract_equip_chunk(filepath, json_data, get_itemname, chunk_name="EquippedItems", group_map=None):

    with open(filepath, 'r', encoding='cp950', errors='ignore') as f:
        content = f.read()

    pattern = (
        r"\[Chunk Items\] Unparsed opcode " + re.escape(chunk_name) +
        r", Length=\d+\s+â†’ Raw hex:\s*\[[^\]]+\]\s*\{([\s\S]*?)^\}"
    )

    match = re.search(pattern, content, re.MULTILINE)
    if not match:
        print(f"æ‰¾ä¸åˆ°æŒ‡å®šchunkï¼({chunk_name})")
        return

    hex_body = match.group(1)
    hex_list = []
    for line in hex_body.splitlines():
        line = re.sub(r'^\s*[0-9A-Fa-f]{4,}\s+', '', line)
        hex_line = re.findall(r'([0-9A-Fa-f]{2})', line)
        if hex_line:
            hex_list.extend(hex_line)

    group_tag = '1901'
    n = len(hex_list)
    group_starts = []
    for i in range(n-1):
        if hex_list[i].lower() == group_tag[:2] and hex_list[i+1].lower() == group_tag[2:]:
            group_starts.append(i)
    group_starts.append(n)

    slot_tags = [
        '1901','1b01','1d01','1c01','1e01','1f01','2001','2101','2301','2701','2b01','2201','2401',
        '2501','2601','2801','2901','2a01','2c01','2d01','1a01'
    ]

    for g in range(len(group_starts)-1):
        group_number = g + 1
        if group_map is None:
            group_map = GROUP_NAME_MAP   # é è¨­ä»ä½¿ç”¨åŸæœ¬é‚£å¥—

        group_name = group_map.get(group_number, f'æœªçŸ¥éƒ¨ä½{group_number}')
        if SHOW_GROUP_NAMES and group_name not in SHOW_GROUP_NAMES:
            continue
        if SHOW_GROUPS and group_number not in SHOW_GROUPS:
            continue

        group_start = group_starts[g]
        group_end = group_starts[g+1]
        group_bytes = hex_list[group_start:group_end]

        group_lines = []
        group_has_data = False

        slot_offsets = []
        for slot in slot_tags:
            slot1, slot2 = slot[:2], slot[2:]
            idx = None
            for i in range(len(group_bytes)-1):
                if group_bytes[i].lower() == slot1 and group_bytes[i+1].lower() == slot2:
                    idx = i
                    break
            slot_offsets.append(idx)

        for si, idx in enumerate(slot_offsets):
            slot_name = slot_tags[si].upper()
            # åªé¡¯ç¤ºæœ‰è§£æé–‹é—œçš„slot
            should_parse = False
            if slot_name == '2201' and SHOW_2201:
                should_parse = True
            elif slot_name == '2301' and SHOW_2301:
                should_parse = True
            elif slot_name == '2701' and SHOW_2701:
                should_parse = True
            elif slot_name == '2D01' and SHOW_2D01:
                should_parse = True
            elif slot_name == '2B01' and SHOW_2B01:
                should_parse = True

            if SHOW_ONLY_PARSED_SLOTS and not should_parse:
                continue

            if idx is None:
                continue

            next_idx = None
            for ni in range(si+1, len(slot_offsets)):
                if slot_offsets[ni] is not None and slot_offsets[ni] > idx:
                    next_idx = slot_offsets[ni]
                    break
            slot_bytes = group_bytes[idx:next_idx] if next_idx else group_bytes[idx:]

            # æ²’æœ‰è³‡æ–™(é™¤äº†slotæ¨™é ­ä»¥å¤–æ²’å…§å®¹)çš„ä¹Ÿä¸é¡¯ç¤º
            if SHOW_ONLY_FILLED and (len(slot_bytes) <= 4):
                continue

            # slotæœ‰è³‡æ–™æ‰é€²ä¾†
            slot_content = []
            show_title = f'---- Slot {slot_name}'
            if SHOW_OFFSET:
                show_title += f' (offset={idx})'
            show_title += ' ----'
            slot_content.append(show_title)
            if SHOW_RAW:
                for j in range(0, len(slot_bytes), 8):
                    slot_content.append(' '.join(slot_bytes[j:j+8]))
            slot_json_name = group_name 
            # ç‰¹æ®Šè§£æ
            if slot_name == '2201':
                try:
                    card_ids = [
                        bytes_to_int_le(slot_bytes[6:9]),
                        bytes_to_int_le(slot_bytes[10:13]),
                        bytes_to_int_le(slot_bytes[14:17]),
                        bytes_to_int_le(slot_bytes[18:21]),
                    ]

                    slot_content.append(f'å››æ´å¡ç‰‡IDï¼š')

                    for i, cid in enumerate(card_ids, 1):

                        # è‹¥æ²’æœ‰è³‡æ–™ â†’ JSON è¦å¯«ç©ºç™½ ""
                        if cid == 0:
                            cname = ""
                            cid = ""
                        else:
                            cname = get_itemname(cid)

                        # å°å‡ºï¼ˆå¦‚æœ cname ç©ºï¼Œå°±é¡¯ç¤ºå¡{i}: ç„¡ï¼‰
                        show_name = cname if cname else ""
                        slot_content.append(f'  å¡{i}: {cid}ã€€{show_name}')

                        # JSON æ¬„ä½ï¼šã€Œé ­ä¸Š_card1ã€ã€Œé ­ä¸Š_card2ã€
                        json_key = f"{group_name}_card{i}"
                        json_data[json_key] = str(cname)  # ç¢ºä¿ JSON ä¸€å¾‹æ˜¯å­—ä¸²

                except Exception:
                    slot_content.append('è§£æå¡ç‰‡IDå¤±æ•—ï¼Œæª¢æŸ¥sloté•·åº¦èˆ‡è³‡æ–™')

            elif slot_name == '2301':
                try:
                    equip_id = bytes_to_int_le(slot_bytes[6:9])

                    if equip_id == 0:
                        equip_name = ""
                    else:
                        equip_name = get_itemname(equip_id)

                    slot_content.append(f'è£å‚™åç¨±IDï¼š{equip_id}ã€€{equip_name if equip_name else "ç„¡"}')
                    json_data[f"{slot_json_name}_equip"] = str(equip_name)
                except:
                    slot_content.append('è§£æè£å‚™åç¨±IDå¤±æ•—ï¼Œæª¢æŸ¥sloté•·åº¦èˆ‡è³‡æ–™')

            elif slot_name == '2701':
                try:
                    refine_lv = int(slot_bytes[6], 16)
                    slot_content.append(f'ç²¾ç…‰ç­‰ç´šï¼š{refine_lv}')
                    json_data[f"{slot_json_name}"] = str(refine_lv)
                except:
                                slot_content.append('è§£æç²¾ç…‰ç­‰ç´šå¤±æ•—ï¼Œæª¢æŸ¥sloté•·åº¦èˆ‡è³‡æ–™')
            elif slot_name == '2D01':
                try:
                    enchant_desc_list = []      # é¡¯ç¤ºç”¨ï¼ˆä¸­æ–‡ï¼‰
                    enchant_json_list = []      # JSON ç”¨ï¼ˆAddExtParam / RaceAddDamage...ï¼‰

                    for i in range(4):
                        id_idx = 6 + i * 5
                        val_idx = 8 + i * 5
                        if val_idx >= len(slot_bytes):
                            break

                        enchant_id = int(slot_bytes[id_idx], 16)
                        enchant_val = int(slot_bytes[val_idx], 16)

                        # æ²’æœ‰é™„é­”
                        if enchant_id == 0 and enchant_val == 0:
                            desc_text = ""
                            json_text = ""
                            show_text = "ç„¡"
                        else:
                            # â†™ ä¸€æ¬¡å–å¾—ä¸­æ–‡æè¿° & JSON æ ¼å¼ï¼ˆä½ å‰é¢å»ºå¥½çš„ functionï¼‰
                            desc_text, json_text = get_enchant_info(enchant_id, enchant_val)

                            show_text = desc_text
                            enchant_desc_list.append(desc_text)
                            enchant_json_list.append(json_text)

                        # é¡¯ç¤º
                        slot_content.append(f'  è©æ¢{i+1}ï¼š{show_text}')

                    # â˜…â˜…â˜… JSONï¼šåªæœ‰ä¸€å€‹ noteï¼ŒæŠŠæ‰€æœ‰é™„é­”ç”¨ \n åˆä½µ â˜…â˜…â˜…
                    if enchant_json_list:
                        json_data[f"{slot_json_name}_note"] = "\n".join(enchant_json_list)
                    else:
                        json_data[f"{slot_json_name}_note"] = ""

                except Exception:
                    slot_content.append("è§£æ2D01é™„é­”è³‡æ–™å¤±æ•—")

            elif slot_name == '2B01':
                try:
                    grade = int(slot_bytes[6], 16)
                    grade_name = GRADE_MAP.get(grade, str(grade))
                    slot_content.append(f'è£å‚™éšç´šï¼š{grade_name}')
                    json_data[f"{slot_json_name}_éšç´š"] = grade_name
                except:
                    slot_content.append('è§£æ2B01è£å‚™éšç´šå¤±æ•—ï¼Œæª¢æŸ¥sloté•·åº¦èˆ‡è³‡æ–™')

            group_lines.extend(slot_content)
            group_has_data = True

        # groupæœ‰ä»»ä½•slotè¦é¡¯ç¤ºæ‰å°å‡º
        if group_has_data:
            print(f'==== {chunk_name} Group {group_number}ï¼ˆ{group_name}ï¼‰====')
            for line in group_lines:
                print(line)
            print()


    print("Done.\n")

def run_rrf_main():
       # 0. è¼‰å…¥ iteminfo
    iteminfo_dict = parse_lub_file("data/iteminfo_new.lua")
    with open("data/EquipmentProperties.lua", "r", encoding="utf-8") as f:
        content = f.read()
    sequipment_data = parse_equipment_blocks(content)
    iteminfo_dict = resolve_name_conflicts(iteminfo_dict ,sequipment_data)#é‡è¤‡ç‰©å“åç¨±åŠ ä¸Šid
    def get_itemname(item_id):
        info = iteminfo_dict.get(item_id)
        if info:
            return info["name"]
        return f"[{item_id}]"

    with open("data/default.json", "r", encoding="utf-8") as f:
        json_data = json.load(f)

    # 1. é¸ RRF â†’ åŸ·è¡Œ exe â†’ ç”¢å‡º temp.txt
    rrf_path, txt_path = run_replay_and_dump()
    if not txt_path:
        #input("æŒ‰ Enter çµæŸ...")
        exit()

    # 2. è§£ææŠ€èƒ½è³‡è¨Š 
    with open(txt_path, "r", encoding="cp950", errors="ignore") as f:
        replay_text = f.read()

    skills = parse_skillinfo_list_from_text(replay_text)
    load_skill_map("data/skillneme.csv") 
    from skill_tree import skill_code_to_name, skill_code_to_id

    print("========== æŠ€èƒ½æ¸…å–® ==========")

    skill_json_list = []   # â˜… ç”¨ä¾†è¼¸å‡º JSON çš„ note

    for code, lv in skills:
        # æŠ€èƒ½åç¨±ï¼šä¾å‰ 23 å­—æ¯”å°
        skill_prefix_map = {k[:23]: v for k, v in skill_code_to_name.items()}
        cname = skill_prefix_map.get(code[:23], code)

        # æŠ€èƒ½ IDï¼šä¹Ÿæ˜¯ä¾å‰ 23 å­—æ¯”å° skill_code_to_id
        skill_prefix_id_map = {k[:23]: v for k, v in skill_code_to_id.items()}
        skill_id = skill_prefix_id_map.get(code[:23], 0)

        # é¡¯ç¤ºç”¨
        print(f"{cname:<23} ç­‰ç´š {lv}")

        # â˜… JSON ç”¨ EnableSkill(æŠ€èƒ½ID, lv)
        if skill_id != 0:
            skill_json_list.append(f"EnableSkill({skill_id}, {lv})")

    print("")
    json_data["æŠ€èƒ½_note"] = "\n".join(skill_json_list)
    # 3.â˜… è§£æè§’è‰² Session è³‡æ–™
    session_data = extract_session_stats(txt_path)

    # è§’è‰²åŸºæœ¬è³‡æ–™
    json_data["BaseLv"] = str(session_data.get("Level", ""))
    json_data["JobLv"] = str(session_data.get("JobLevel", ""))
    job_id = session_data.get("Job")
    job_info = job_dict.get(job_id)
    json_data["JOB"] = str(job_info["name"]) if job_info else ""

    for k in ["Str","Agi","Vit","Int","Dex","Luk","POW","STA","WIS","SPL","CON","CRT"]:
        if k in session_data:
            json_data[k.upper()] = str(session_data[k])

    print("========== è§’è‰²è³‡è¨Š ==========")
    if "Charactername" in session_data:
        print(f"è§’è‰²åç¨±ï¼š{session_data['Charactername']}")
    if "Job" in session_data:
        job_id = session_data["Job"]
        job_info = job_dict.get(job_id)

        if job_info:
            job_name = job_info.get("name", f"æœªçŸ¥è·æ¥­({job_id})")
            print(f"è·æ¥­ï¼š{job_name}")
        else:
            print(f"è·æ¥­ï¼šæœªçŸ¥è·æ¥­ (ID: {job_id})")
    if "Level" in session_data:
        print(f"è§’è‰²ç­‰ç´šï¼š{session_data['Level']}")
    if "JobLevel" in session_data:
        print(f"Job ç­‰ç´šï¼š{session_data['JobLevel']}")

    print("------ åŸºç¤ç´ è³ª ------")
    for stat in ["Str", "Agi", "Vit", "Int", "Dex", "Luk", "POW", "STA", "WIS", "SPL", "CON", "CRT"]:
        if stat in session_data:
            print(f"{stat}: {session_data[stat]}")
    print("")
    
    # 4. ç”¨ temp.txt é–‹å§‹è§£æ
    extract_equip_chunk(txt_path, json_data, get_itemname,'EquippedItems', GROUP_NAME_MAP)
    extract_equip_chunk(txt_path, json_data, get_itemname,'EquippedShadowItems', Shadow_GROUP_NAME_MAP)


    # 5. è§£æå®Œç•¢ â†’ åˆªé™¤ temp.txt
    try:
        if os.path.exists(txt_path):
            os.remove(txt_path)
            print(f"å·²åˆªé™¤æš«å­˜æª”ï¼š{txt_path}")
    except Exception as e:
        print(f"åˆªé™¤ {txt_path} æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

    # ä¾ç…§è¼¸å…¥çš„ RRF è‡ªå‹•å‘½å json
    rrf_filename = os.path.basename(rrf_path)        # ä¾‹ï¼šabc.rrf
    json_name = os.path.splitext(rrf_filename)[0] + ".json"
    json_output_path = os.path.join("tmp", json_name)

    with open(json_output_path, "w", encoding="utf-8") as f:
        json.dump(json_data, f, ensure_ascii=False, indent=2)
    # === å‘Šè¨´ GUI è¼¸å‡ºçš„ json æ˜¯å“ªå€‹ ===
    with open("tmp/rrf_output_path.txt", "w", encoding="utf-8") as f:
        f.write(json_output_path)

    print(f"JSON å·²è¼¸å‡ºç‚º {json_output_path}")
    #input("æŒ‰ Enter çµæŸ...")

    return json_output_path

if __name__ == "__main__":
    run_rrf_main()